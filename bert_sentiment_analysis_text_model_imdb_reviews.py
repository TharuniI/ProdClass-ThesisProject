# -*- coding: utf-8 -*-
"""bert_sentiment_analysis_text_model_imdb_reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OFHuZWDz3HwodADNPiXZh_SbpRmY9ohQ

Install and Import
"""

!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html

!pip install transformers requests beautifulsoup4 pandas numpy

!pip3 install bertopic[all]

import numpy as np
import pandas as pd
import tensorflow as tf
from bertopic import BERTopic

import torch
import json 

import gzip
import re
import requests
import string
from string import punctuation
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from transformers import AutoTokenizer, AutoModelForSequenceClassification

"""**Data Loading and Cleaning**"""

#!wget deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Home_and_Kitchen.csv
!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz

# Load the Data
df = pd.read_csv('Star Wars_ Episode VIII - The Last Jedi 2017.csv')
df.head()

# Remove unneccessary columns
df = df.drop(['total', 'username', 'title', 'rating'], axis=1)

df.head()

# Remove HTML Tags
import re

TAG_RE = re.compile(r'<[^>]+>')

def remove_tags(text):
    return TAG_RE.sub(' ', text)

df['review tag'] = df['review'].apply(remove_tags)
df.head()

# Remove punctations and unnecessary words
def get_text_processing(text):
    stpword = stopwords.words('english')
    no_punctuation = [char for char in text if char not in string.punctuation]
    no_punctuation = ''.join(no_punctuation)
    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])

df['review clean'] = df['review tag'].apply(get_text_processing)
df = df.drop(['review', 'review tag'], axis=1)

df.head()

"""Instantiate Model for Sentiment Analysis"""

tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')
model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')

def sentiment_score(review):
    tokens = tokenizer.encode(review, return_tensors='pt')
    result = model(tokens)
    return int(torch.argmax(result.logits))+1

df['sentiment'] = df['review clean'].apply(lambda x: sentiment_score(x[:512]))

df.tail()

"""Split Table into 3 """

positive_table = df.loc[df['sentiment'] >= 4]
positive_table.head()

negative_table = df.loc[df['sentiment'] <= 2]
negative_table.head()

neutral = df.loc[df['sentiment'] == 3]
neutral.head()

"""Instantiate Model for Text Modelling"""

def get_topics(data):
  topic_model = BERTopic(language="english", calculate_probabilities=True) # We need the probabilities to visualize
  topics, _ = topic_model.fit_transform(data)

  # Get the most frequent topics
  topic_freq = topic_model.get_topic_freq()
  outliers = topic_freq['Count'][topic_freq['Topic']==-1].iloc[0]
  return topic_freq

positive_topic = get_topics(df['review clean'])
# positive_topic.get_topic(topic_freq['Topic'].iloc[1])

positive_topic.tail()

positive_topic['Topic'].iloc[1]

