# -*- coding: utf-8 -*-
"""bert_text_model_sentiment_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MTOwVfHEH5lh2Nm9pHiisBt_TBkfuTQf

**Install and Import**
"""

!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html

!pip3 install bertopic[all]

import numpy as np
import pandas as pd
import tensorflow as tf
from bertopic import BERTopic

import torch
import json 

import gzip
import re
import requests
import string
from string import punctuation
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from transformers import AutoTokenizer, AutoModelForSequenceClassification

"""**Data Load and Clean**

Items Data
"""

# Open dataset that contains details of each phone
df = pd.read_csv('amazon_phone_items.csv')
df.head()

# Extract only the Samsung rows, and remove unneccessary columns
samsung_phones = df.loc[df['brand'] == 'Samsung']
samsung_phones = samsung_phones.drop(['url', 'image', 'reviewUrl', 'originalPrice'], axis=1)

samsung_phones = samsung_phones.reset_index()
samsung_phones.head()

# Find the phone with the max number of reviews
max = np.argmax(samsung_phones['totalReviews'])
max_index = samsung_phones['title'][max]
max_index

"""Review Data"""

# Open dataset that has all the reviews
df2 = pd.read_csv('amazon_phone_reviews.csv')
df2.head()

# Extract only the Samsung Galaxy Note 3 review rows, and remove unneccessary columns
note_3 = df2.loc[df2['asin'] == samsung_phones['asin'][max]]
note_3 = note_3.drop(['asin','name', 'verified', 'title'], axis=1)

note_3 = note_3.reset_index()
note_3.head()

"""Clean Data"""

# Remove HTML Tags, if any
TAG_RE = re.compile(r'<[^>]+>')

def remove_tags(text):
    return TAG_RE.sub(' ', text)

note_3['review tag'] = note_3['body'].apply(remove_tags)
note_3.head()

# Remove punctations and unnecessary words
def get_text_processing(text):
    stpword = stopwords.words('english')
    no_punctuation = [char for char in text if char not in string.punctuation]
    no_punctuation = ''.join(no_punctuation)
    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])

note_3['review'] = note_3['review tag'].apply(get_text_processing)
note_3 = note_3.drop(['body', 'review tag'], axis=1)

note_3.head()

"""**Sentiment Analysis**"""

tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')
model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')

def sentiment_score(review):
    tokens = tokenizer.encode(review, return_tensors='pt')
    result = model(tokens)
    return int(torch.argmax(result.logits))+1

note_3['sentiment'] = note_3['review'].apply(lambda x: sentiment_score(x[:512]))

note_3.head()

"""Split into 3 tables"""

positive_table = note_3.loc[note_3['sentiment'] >= 4]
positive_table = positive_table.reset_index()
positive_table = positive_table.drop(['level_0', 'index'], axis=1)
positive_table.head()

negative_table = note_3.loc[note_3['sentiment'] <= 2]
negative_table = negative_table.reset_index()
negative_table = negative_table.drop(['level_0', 'index'], axis=1)
negative_table.head()

neutral = note_3.loc[note_3['sentiment'] == 3]
neutral = neutral.reset_index()
neutral = neutral.drop(['level_0', 'index'], axis=1)
neutral.head()

"""**Text Modelling**"""

def find_topics(data):
  topic_model = BERTopic(language="english", calculate_probabilities=True) # We need the probabilities to visualize
  topics, _ = topic_model.fit_transform(data)

  # Get the most frequent topics
  topic_freq = topic_model.get_topic_freq()
  outliers = topic_freq['Count'][topic_freq['Topic']==-1].iloc[0]
  return topic_model.get_topic(topic_freq['Topic'].iloc[0])

positive_topics = find_topics(positive_table['review'])
positive_topics

negative_topics = find_topics(negative_table['review'])
negative_topics

neutral_topics = find_topics(neutral['review'])
neutral_topics